[package]
name = "rust_tokenizers"
version = "8.1.1"
authors = ["Guillaume Becquin <guillaume.becquin@gmail.com>"]
edition = "2018"
description = "High performance tokenizers for Rust"
repository = "https://github.com/guillaume-be/rust-tokenizers"
license = "Apache-2.0"
readme = "README.md"
build = "build.rs"
keywords = ["nlp", "machine-learning", "tokenizer"]

[dependencies]
csv = "1"
unicode-normalization = "0.1"
rayon = "1"
lazy_static = "1"
itertools = "0.11"
serde = {version = "1", features = ["derive"]}
serde_json = "1"
regex = "1"
protobuf = "2"
hashbrown = "0.14"
unicode-normalization-alignments = "0.1.12"
thiserror = "1"

[dev-dependencies]
tempfile = "3"
dirs = "5"
cached-path = { version = "0.6", default-features = false }
anyhow = "1"

[build-dependencies]
protobuf-codegen-pure = {version = "2", optional = true}

[features]
default = ["default-tls"]
proto-compile = [ "protobuf-codegen-pure" ]
default-tls = ["cached-path/default-tls"]
rustls-tls = ["cached-path/rustls-tls"]

[lib]
name = "rust_tokenizers"
path = "src/lib.rs"
crate-type = ["lib"]
